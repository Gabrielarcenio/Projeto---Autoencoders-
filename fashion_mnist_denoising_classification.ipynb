{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.layers import Dense, Input, Activation, Dropout\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o conjunto de dados MNIST\n",
    "(x_train, y_train), (x_test, y_test) = (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "#yn = y_train.to_numpy()\n",
    "print(y_train.max())\n",
    "\n",
    "# Normalizando os valores dos pixels para o intervalo [0, 1]\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# Transformando as imagens em vetores unidimensionais (784 pixels)\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "# Aplicação de ruído nos dados e armazenando e variáveis acessórias\n",
    "noise_factor = 0.3\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
    "\n",
    "#print(len(x_train))\n",
    "#print(x_train.shape[1:])\n",
    "#print(np.prod(x_train.shape[1:]))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "#print(x_train.view)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a dimensão da representação codificada\n",
    "n_latent = 120\n",
    "\n",
    "# Criando o modelo do autoencoder\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
    "model.add(Dense(300, activation=\"relu\"))\n",
    "model.add(Dense(n_latent, activation=\"relu\"))\n",
    "model.add(Dense(300, activation=\"relu\"))\n",
    "model.add(Dense(784, activation=\"sigmoid\"))\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o autoencoder\n",
    "model.fit(x_train, x_train, epochs=30, batch_size=256, shuffle=True, validation_data=(x_test, x_test))\n",
    "\n",
    "# Codificando e decodificando as imagens de teste sem ruído\n",
    "encoded_imgs = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando algumas imagens originais sem ruído e reconstruídas\n",
    "n = 15\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Imagem original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Imagem reconstruída\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(encoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificando e decodificando as imagens de teste com ruído\n",
    "encoded_imgs = model.predict(x_test_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando algumas imagens originais com ruído e reconstruídas\n",
    "n = 15\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Imagem original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Imagem reconstruída\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(encoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "hidden_units = 256\n",
    "dropout = 0.45\n",
    "input_size = x_train.shape[1]\n",
    "num_labels = len(np.unique(y_train))\n",
    "\n",
    "# model is a 3-layer MLP with ReLU and dropout after each layer\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(hidden_units, input_dim=input_size))\n",
    "model2.add(Activation('relu'))\n",
    "#model2.add(Dropout(dropout))\n",
    "model2.add(Dense(hidden_units))\n",
    "model2.add(Activation('relu'))\n",
    "#model2.add(Dropout(dropout))\n",
    "model2.add(Dense(num_labels))\n",
    "model2.add(Activation('softmax'))\n",
    "\n",
    "model2.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(x_train, y_train, epochs=50, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model2.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print(\"\\nTeste de Acurácia Classificação sem Ruído: %.1f%%\" % (100.0 * acc))\n",
    "loss, acc = model2.evaluate(x_test_noisy, y_test, batch_size=batch_size)\n",
    "print(\"\\nTeste de Acurácia Classificação com Ruído: %.1f%%\" % (100.0 * acc))\n",
    "loss, acc = model2.evaluate(encoded_imgs, y_test, batch_size=batch_size)\n",
    "print(\"\\nTeste de Acurácia Classificação das Imagens Recuperadas do Ruído: %.1f%%\" % (100.0 * acc))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
